---

### âœ… `README.md`

```markdown
# CIFAR-100 Image Classification ðŸ§ ðŸ“Š

This project demonstrates image classification on the **CIFAR-100 dataset** using two different approaches:

1. **Custom CNN from Scratch** with:
   - Data Augmentation
   - Learning Rate Scheduler
   - Early Stopping
2. **Transfer Learning** using **ResNet-50**

---

## ðŸ“ Project Structure

```

cifar100-classification/
â”œâ”€â”€ scratch\_model.py          # CNN from scratch with DA, LR scheduler, early stop
â”œâ”€â”€ resnet50\_transfer.py      # Transfer learning with ResNet-50 (optional)
â”œâ”€â”€ utils.py                  # Data preprocessing and callbacks
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## ðŸ§  Dataset

**CIFAR-100** consists of 60,000 color images (32x32), 100 classes (600 images/class), with:
- 50,000 training images
- 10,000 test images

Itâ€™s automatically downloaded via `tf.keras.datasets`.

---

## ðŸš€ Model Training

### âœ… CNN From Scratch

Trained using:
- `Conv2D`, `MaxPooling`, `BatchNorm`, `Dropout`, `Dense`
- **Data Augmentation** (`ImageDataGenerator` or `tf.image`)
- **Learning Rate Scheduler**: `ReduceLROnPlateau`
- **Early Stopping**: Monitored validation accuracy

Run:

```bash
python scratch_model.py
````

### ðŸ”„ Transfer Learning with ResNet-50

* Resize CIFAR-100 images to 224Ã—224
* Use `tf.keras.applications.ResNet50`
* Fine-tune final layers or train top layers only

Run:

```bash
python resnet50_transfer.py
```

---

## ðŸ“Š Results

| Model                | Top-1 Accuracy | Top-5 Accuracy | Notes                                 |
| -------------------- | -------------- | -------------- | ------------------------------------- |
| CNN (Scratch + DA)   | **65.51%**     | **89.02%**     | With Data Augmentation, LR, EarlyStop |
| ResNet-50 (Transfer) | \~65â€“75%       | \~85â€“90%       | Coming soon                           |

### ðŸ” CNN Final Output (Test Set)

```
313/313 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 16ms/step - accuracy: 0.6516 - loss: 1.2594 - top_k_categorical_accuracy: 0.8879
Test loss: 1.2397
Test accuracy: 65.51%
Test top-5 accuracy: 89.02%
```

---

## âš™ï¸ Features Used

* âœ… **Data Augmentation**: Random flip, crop, rotation, zoom
* âœ… **Learning Rate Scheduler**: `ReduceLROnPlateau` on val\_accuracy
* âœ… **Early Stopping**: Stops training after 5 epochs without improvement
* âœ… **Top-5 Accuracy** Metric

---

## ðŸ§° Requirements

```
tensorflow>=2.12.0
numpy
matplotlib
```

Install with:

```bash
pip install -r requirements.txt
```

---

## ðŸ“Ž References

* [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)
* [ResNet Paper](https://arxiv.org/abs/1512.03385)

---

## ðŸ™Œ Acknowledgments

Built as part of my deep learning journey, exploring the effectiveness of both custom architectures and transfer learning techniques on real-world datasets.

---

```

Let me know if you want:
- A `requirements.txt` file auto-generated
- To export this README as a `.md` file
- Or include the exact augmentation settings you used (`rotation_range`, `zoom_range`, etc.) in the README too.
```
